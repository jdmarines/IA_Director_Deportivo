# main_app.py

import streamlit as st
from dotenv import load_dotenv

# Importamos las clases de nuestros agentes
from agents.quantitative_agent import QuantitativeAgent
from agents.qualitative_agent import QualitativeAgent

# Importamos lo necesario de LangChain y Gemini
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain

# ----- C√ìDIGO DE DIAGN√ìSTICO -----
import os
import google.generativeai as genai

with st.expander("üîç VERIFICACI√ìN DE DIAGN√ìSTICO DE API"):
    st.write("Verificando la configuraci√≥n de la API de Google...")
    api_key_exists = "GOOGLE_API_KEY" in os.environ and os.environ["GOOGLE_API_KEY"]

    if not api_key_exists:
        st.error("ERROR: La variable de entorno GOOGLE_API_KEY no se encontr√≥ en los Secrets de Streamlit.")
    else:
        st.success("OK: La variable de entorno GOOGLE_API_KEY est√° cargada.")
        try:
            genai.configure(api_key=os.environ["GOOGLE_API_KEY"])
            st.write("**Modelos disponibles para tu API Key:**")
            model_list = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            if not model_list:
                st.warning("No se encontraron modelos compatibles con 'generateContent'.")
            else:
                st.dataframe(model_list)
        except Exception as e:
            st.error(f"ERROR al contactar la API de Google: {e}")
# ----- FIN DEL C√ìDIGO DE DIAGN√ìSTICO -----

# Cargar la variable de entorno con la API Key de Google
load_dotenv()

# --- CONFIGURACI√ìN DE LA APLICACI√ìN DE STREAMLIT ---
st.set_page_config(
    page_title="ScoutAI - Asistente de Scouting",
    page_icon="‚öΩ",
    layout="centered"
)

st.title("‚öΩ ScoutAI: Tu Asistente de Scouting")
st.caption("Una herramienta para an√°lisis cuantitativo y cualitativo de jugadores.")

# --- INICIALIZACI√ìN DE LOS AGENTES (USANDO CACH√â DE STREAMLIT) ---
# st.cache_resource permite que los agentes se carguen una sola vez y no en cada recarga.
# Esto es crucial para no reconstruir la base de datos vectorial cada vez.
@st.cache_resource
def initialize_agents():
    """
    Carga y prepara ambos agentes para ser utilizados.
    """
    print("Inicializando agentes por primera vez...")
    # Aseg√∫rate de que la ruta al CSV es correcta
    quantitative_agent = QuantitativeAgent(csv_path="data/stats.csv") 
    qualitative_agent = QualitativeAgent()
    print("Agentes listos.")
    return quantitative_agent, qualitative_agent

quantitative_agent, qualitative_agent = initialize_agents()

# --- L√ìGICA DEL ENRUTADOR (ROUTER) CON GEMINI ---
@st.cache_resource
def initialize_router_chain():
    """
    Crea la cadena de LangChain que decidir√° qu√© agente usar.
    """
    print("Inicializando cadena de enrutamiento...")
    
    # Usamos Gemini Flash por su velocidad y bajo costo
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", temperature=0.0)

    # El prompt es la "inteligencia" del enrutador. Le ense√±amos a clasificar la pregunta.
    router_template = """
    Tu tarea es clasificar la pregunta de un usuario para un sistema de scouting de f√∫tbol.
    Debes decidir si la pregunta es 'cuantitativa' o 'cualitativa'.

    - 'cuantitativa': Se refiere a estad√≠sticas, n√∫meros, m√©tricas, rankings, datos espec√≠ficos.
      Ejemplos: "¬øQui√©n es el m√°ximo goleador?", "¬øCu√°ntos a√±os tiene Messi?", "Top 5 asistidores".
    - 'cualitativa': Se refiere a opiniones, descripciones de habilidades, estilo de juego, potencial, comparaci√≥n de perfiles.
      Ejemplos: "¬øC√≥mo juega Lamine Yamal?", "Fortalezas y debilidades de Mbapp√©", "¬øQu√© jugador es un buen regateador?".

    Basado en la pregunta, responde √∫nicamente con la palabra 'cuantitativa' o 'cualitativa'.

    Pregunta del usuario:
    {user_question}

    Clasificaci√≥n:
    """

    router_prompt = PromptTemplate(
        template=router_template,
        input_variables=["user_question"]
    )

    return LLMChain(llm=llm, prompt=router_prompt)

router_chain = initialize_router_chain()


# --- INTERFAZ DE USUARIO ---
user_question = st.text_input(
    "Haz tu pregunta sobre un jugador:",
    placeholder="Ej: ¬øCu√°les son las estad√≠sticas de Haaland? o ¬øC√≥mo es el estilo de juego de Bellingham?"
)

if user_question:
    with st.spinner("Analizando pregunta y buscando informaci√≥n..."):
        # 1. Usamos el enrutador para clasificar la pregunta
        st.info("Clasificando pregunta...")
        route = router_chain.run(user_question).strip().lower()
        st.write(f"**Tipo de consulta detectada:** `{route}`")

        # 2. Ejecutamos el agente correspondiente
        if "cuantitativa" in route:
            # Para preguntas cuantitativas, intentamos extraer la m√©trica o el jugador
            # Esta es una l√≥gica simple, se podr√≠a mejorar con otro llamado al LLM
            if "top" in user_question.lower() or "m√°ximo" in user_question.lower():
                # Asumimos una m√©trica com√∫n como Goles (Gls) si no se especifica
                metric_to_find = "Gls" # Podr√≠as hacer esto m√°s inteligente
                response = quantitative_agent.find_top_players(metric=metric_to_find)
            else:
                # Extraemos el nombre del jugador (l√≥gica simple)
                # Se asume que el nombre viene despu√©s de "de" o es la √∫ltima parte
                parts = user_question.split("de ")
                player_name = parts[-1].replace("?", "").strip()
                response = quantitative_agent.get_player_stats(player_name=player_name)
            
            st.json(response) # Mostramos el JSON/dict de forma bonita

        elif "cualitativa" in route:
            response = qualitative_agent.answer_question(query=user_question)
            st.markdown(response)
        
        else:
            # Fallback si el enrutador no responde lo esperado
            st.error("No se pudo determinar el tipo de pregunta. Intenta reformularla.")
